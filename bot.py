#!/usr/bin/env python3
"""
Telegram-–±–æ—Ç –¥–ª—è HR-–æ—Ç–¥–µ–ª–∞ –∫–æ–º–ø–∞–Ω–∏–∏ "–ú–µ—á–µ–ª"
–í–µ—Ä—Å–∏—è 12.45 ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥:
‚Ä¢ –í—ã–Ω–µ—Å–µ–Ω—ã utils.py, web_panel.py, stats.py
‚Ä¢ bot.py —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ Telegram-–ª–æ–≥–∏–∫—É –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é
‚Ä¢ –ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å search_engine.py v5.2 –∏ meme_handler.py v9.2
‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è Render Free
"""
import os
import sys
import asyncio
import logging
import json
import time
import functools
import hashlib
import re
import io
import inspect
import signal
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from collections import defaultdict, deque

# ------------------------------------------------------------
#  –ü–†–û–í–ï–†–ö–ê –ö–†–ò–¢–ò–ß–ï–°–ö–ò–• –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô
# ------------------------------------------------------------
def check_critical_dependencies():
    try:
        from importlib.metadata import version, PackageNotFoundError
    except ImportError:
        try:
            from importlib_metadata import version, PackageNotFoundError
        except ImportError:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å importlib.metadata", file=sys.stderr)
            sys.exit(1)
    critical_packages = ['quart', 'python-telegram-bot', 'hypercorn', 'pandas']
    missing = []
    for pkg in critical_packages:
        try:
            ver = version(pkg)
            print(f"‚úÖ {pkg} –≤–µ—Ä—Å–∏—è {ver} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
        except PackageNotFoundError:
            missing.append(pkg)
    if missing:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {', '.join(missing)}", file=sys.stderr)
        sys.exit(1)
    print("‚úÖ –í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")

check_critical_dependencies()

# ------------------------------------------------------------
#  –ò–ú–ü–û–†–¢–´ (–±–µ–∑ psutil –∏ TelegramError ‚Äî –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è)
# ------------------------------------------------------------
from quart import Quart, request, jsonify, make_response, render_template_string
import hypercorn
from hypercorn.config import Config
from hypercorn.asyncio import serve
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    filters,
    ContextTypes,
    ApplicationBuilder
)
import pandas as pd
from openpyxl import Workbook
from openpyxl.styles import Font
from openpyxl.utils import get_column_letter
from dotenv import load_dotenv

# ------------------------------------------------------------
#  –ò–ú–ü–û–†–¢ –ú–û–î–£–õ–Ø –ú–ï–ú–û–í
# ------------------------------------------------------------
try:
    from meme_handler import (
        init_meme_handler,
        close_meme_handler,
        meme_command,
        meme_subscribe_command,
        meme_unsubscribe_command,
        get_meme_handler
    )
    MEME_MODULE_AVAILABLE = True
    print("‚úÖ –ú–æ–¥—É–ª—å –º–µ–º–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω")
except ImportError:
    MEME_MODULE_AVAILABLE = False
    print("‚ö†Ô∏è –ú–æ–¥—É–ª—å –º–µ–º–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω, –∫–æ–º–∞–Ω–¥—ã /–º–µ–º –∏ –ø–æ–¥–ø–∏—Å–∫–∏ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
    # –ó–∞–≥–ª—É—à–∫–∏
    async def init_meme_handler(*args, **kwargs): pass
    async def close_meme_handler(): pass
    async def meme_command(*args, **kwargs): pass
    async def meme_subscribe_command(*args, **kwargs): pass
    async def meme_unsubscribe_command(*args, **kwargs): pass
    def get_meme_handler(): return None

# ------------------------------------------------------------
#  –§–£–ù–ö–¶–ò–Ø –õ–ï–í–ï–ù–®–¢–ï–ô–ù–ê (–î–õ–Ø –í–°–¢–†–û–ï–ù–ù–û–ì–û –î–í–ò–ñ–ö–ê)
# ------------------------------------------------------------
def levenshtein_distance(s1: str, s2: str) -> int:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞ –º–µ–∂–¥—É –¥–≤—É–º—è —Å—Ç—Ä–æ–∫–∞–º–∏."""
    if len(s1) < len(s2):
        return levenshtein_distance(s2, s1)
    if len(s2) == 0:
        return len(s1)
    previous_row = range(len(s2) + 1)
    for i, c1 in enumerate(s1):
        current_row = [i + 1]
        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row
    return previous_row[-1]

# ------------------------------------------------------------
#  –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø
# ------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('bot.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ------------------------------------------------------------
#  –ü–ï–†–ï–ú–ï–ù–ù–´–ï –û–ö–†–£–ñ–ï–ù–ò–Ø
# ------------------------------------------------------------
load_dotenv()

def get_bot_token() -> str:
    token = os.getenv('TELEGRAM_BOT_TOKEN')
    if token:
        return token
    token = os.getenv('BOT_TOKEN')
    if token:
        logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç–∞—Ä–µ–≤—à–µ–µ –∏–º—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π BOT_TOKEN. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –≤ TELEGRAM_BOT_TOKEN.")
        return token
    return ''

def validate_token(token: str) -> bool:
    return bool(token and len(token) > 30 and ':' in token)

BOT_TOKEN = get_bot_token()
if not validate_token(BOT_TOKEN):
    logger.critical("‚ùå TELEGRAM_BOT_TOKEN (–∏–ª–∏ BOT_TOKEN) –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç")
    sys.exit(1)

RENDER = os.getenv('RENDER', 'false').lower() == 'true'
PORT = int(os.getenv('PORT', 8080))
WEBHOOK_SECRET = os.getenv('WEBHOOK_SECRET', '')
if not WEBHOOK_SECRET:
    WEBHOOK_SECRET = 'mechel_hr_dev_' + hashlib.md5(BOT_TOKEN.encode()).hexdigest()[:16]
    if RENDER:
        logger.warning("‚ö†Ô∏è WEBHOOK_SECRET —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤—Ä—É—á–Ω—É—é –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞.")

WEBHOOK_PATH = f"/webhook/{WEBHOOK_SECRET}"
WEBHOOK_URL = os.getenv('WEBHOOK_URL', '')
if RENDER and not WEBHOOK_URL:
    logger.critical("‚ùå –ù–∞ Render WEBHOOK_URL –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")
    sys.exit(1)

BASE_URL = f"http://localhost:{PORT}" if not RENDER else WEBHOOK_URL.rstrip('/')
ADMIN_IDS = []
try:
    admin_str = os.getenv('ADMIN_IDS', '')
    if admin_str:
        ADMIN_IDS = [int(x.strip()) for x in admin_str.split(',') if x.strip().isdigit()]
        logger.info(f"‚úÖ –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—ã: {ADMIN_IDS}")
except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ ADMIN_IDS: {e}")

# ------------------------------------------------------------
#  –ù–ï–§–ê–¢–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –û–ü–¶–ò–û–ù–ê–õ–¨–ù–´–• –§–ê–ô–õ–û–í
# ------------------------------------------------------------
def check_optional_files():
    optional_files = ['search_engine.py']
    missing = []
    for file in optional_files:
        if not os.path.exists(file):
            missing.append(file)
    if missing:
        logger.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã: {', '.join(missing)}")
        logger.warning("‚ö†Ô∏è –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª")
    else:
        logger.info("‚úÖ –í—Å–µ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")

check_optional_files()

# ------------------------------------------------------------
#  –í–°–¢–†–û–ï–ù–ù–´–ô –ü–û–ò–°–ö–û–í–´–ô –î–í–ò–ñ–û–ö (–° –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ï–ô –ò –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø–ú–ò)
# ------------------------------------------------------------
class BuiltinSearchEngine:
    def __init__(self, max_cache_size: int = 1000):
        self.max_cache_size = max_cache_size
        self.cache = {}
        self.cache_ttl = {}
        self.faq_data = self._load_faq_data()
        self.stop_words = {
            '–∫–∞–∫', '—á—Ç–æ', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '—Å–∫–æ–ª—å–∫–æ', '—á–µ–π',
            '–∞', '–∏', '–Ω–æ', '–∏–ª–∏', '–µ—Å–ª–∏', '—Ç–æ', '–∂–µ', '–±—ã', '–≤', '–Ω–∞', '—Å', '–ø–æ',
            '–æ', '–æ–±', '–æ—Ç', '–¥–æ', '–¥–ª—è', '–∏–∑', '—É', '–Ω–µ', '–Ω–µ—Ç', '–¥–∞', '—ç—Ç–æ',
            '—Ç–æ—Ç', '—ç—Ç–æ—Ç', '—Ç–∞–∫–æ–π', '–∫–∞–∫–æ–π', '–≤—Å–µ', '–≤—Å—ë', '–µ–≥–æ', '–µ–µ', '–∏—Ö'
        }
        logger.info(f"‚úÖ BuiltinSearchEngine: –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.faq_data)} –≤–æ–ø—Ä–æ—Å–æ–≤ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–µ—á—ë—Ç–∫–∏–π –ø–æ–∏—Å–∫)")

    def _normalize_faq_item(self, item: Any) -> Dict[str, Any]:
        if isinstance(item, dict):
            return {
                'id': item.get('id', hash(item.get('question', '')) % 1000000),
                'question': item.get('question', ''),
                'answer': item.get('answer', ''),
                'category': item.get('category', '–ë–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏'),
                'keywords': item.get('keywords', [])
            }
        return {
            'id': getattr(item, 'id', hash(getattr(item, 'question', '')) % 1000000),
            'question': getattr(item, 'question', ''),
            'answer': getattr(item, 'answer', ''),
            'category': getattr(item, 'category', '–ë–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏'),
            'keywords': getattr(item, 'keywords', [])
        }

    def _load_faq_data(self) -> List[Dict[str, Any]]:
        data = []
        try:
            with open('faq.json', 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
                for idx, item in enumerate(raw_data, start=1):
                    normalized = self._normalize_faq_item(item)
                    if not normalized.get('id'):
                        normalized['id'] = idx
                    data.append(normalized)
            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ faq.json")
            return data
        except FileNotFoundError:
            logger.warning("‚ö†Ô∏è –§–∞–π–ª faq.json –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã")
        except json.JSONDecodeError as e:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ faq.json: {e}. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã")
        return self._get_backup_questions()

    def _get_backup_questions(self) -> List[Dict[str, Any]]:
        return [
            {
                "id": 1,
                "question": "–ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å —Å–ø—Ä–∞–≤–∫—É –æ –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç–µ?",
                "answer": "–°–ø—Ä–∞–≤–∫—É –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –≤ –æ—Ç–¥–µ–ª–µ –∫–∞–¥—Ä–æ–≤ (–∫–∞–±. 205) –∏–ª–∏ —á–µ—Ä–µ–∑ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ—Ä—Ç–∞–ª.",
                "category": "–î–æ–∫—É–º–µ–Ω—Ç—ã",
                "keywords": ["—Å–ø—Ä–∞–≤–∫–∞", "–∑–∞—Ä–ø–ª–∞—Ç–∞", "–∑–∞—Ä–∞–±–æ—Ç–Ω–∞—è", "–ø–ª–∞—Ç–∞"]
            },
            {
                "id": 2,
                "question": "–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –æ—Ç–ø—É—Å–∫?",
                "answer": "–ó–∞—è–≤–ª–µ–Ω–∏–µ –≤ –ø–æ—Ä—Ç–∞–ª–µ ‚Üí —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ —Å —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º ‚Üí –æ—Ç–¥–µ–ª –∫–∞–¥—Ä–æ–≤ ‚Üí –ø—Ä–∏–∫–∞–∑.",
                "category": "–û—Ç–ø—É—Å–∫",
                "keywords": ["–æ—Ç–ø—É—Å–∫", "–æ—Ñ–æ—Ä–º–∏—Ç—å", "–∑–∞—è–≤–ª–µ–Ω–∏–µ", "–æ—Ç–¥—ã—Ö"]
            }
        ]

    def _normalize_query(self, query: str) -> str:
        query = query.lower().strip()
        query = re.sub(r'[^\w\s]', ' ', query)
        words = [w for w in query.split() if w not in self.stop_words and len(w) > 2]
        norm = []
        for w in words:
            if w.endswith('—Ç—å—Å—è'): w = w[:-4] + '—Ç—å'
            elif w.endswith('—Ç—Å—è'): w = w[:-3] + '—Ç—å—Å—è'
            elif w.endswith('–∞—Ç—å') and len(w) > 4: w = w[:-3]
            elif w.endswith('—è—Ç—å') and len(w) > 4: w = w[:-3]
            elif w.endswith('–∏—Ç—å') and len(w) > 4: w = w[:-3]
            elif w.endswith('–µ—Ç—å') and len(w) > 4: w = w[:-3]
            elif w.endswith('—ã–π') or w.endswith('–∏–π') or w.endswith('–æ–π'): w = w[:-2]
            elif w.endswith('–∞—è') or w.endswith('—è—è'): w = w[:-2]
            elif w.endswith('–æ–µ') or w.endswith('–µ–µ'): w = w[:-2]
            norm.append(w)
        return ' '.join(norm)

    def _quick_match(self, norm_query: str, item: Dict[str, Any]) -> bool:
        if not norm_query:
            return False
        q_words = set(norm_query.split())
        norm_question = self._normalize_query(item['question'])
        q_words_question = set(norm_question.split())
        if q_words.intersection(q_words_question):
            return True
        norm_keywords = ' '.join(item.get('keywords', [])).lower()
        if norm_keywords:
            q_words_keywords = set(norm_keywords.split())
            if q_words.intersection(q_words_keywords):
                return True
        return False

    def _calculate_full_score(self, norm_query: str, item: Dict[str, Any]) -> float:
        score = 0.0
        norm_question = self._normalize_query(item['question'])
        norm_answer = self._normalize_query(item['answer'])
        norm_keywords = ' '.join(item.get('keywords', [])).lower()
        q_words = set(norm_query.split())

        if norm_query == norm_question:
            return 100.0
        if norm_query in norm_question:
            score += 50.0
        if len(norm_query) >= 4 and norm_question:
            lev_dist = levenshtein_distance(norm_query, norm_question)
            if lev_dist == 0:
                return 100.0
            elif lev_dist <= 2:
                score += 40.0
            elif lev_dist <= 4:
                score += 20.0
        if norm_keywords:
            kw_lev = levenshtein_distance(norm_query, norm_keywords[:len(norm_query)+5])
            if kw_lev <= 2:
                score += 30.0

        q_words_question = set(norm_question.split())
        common_q = q_words.intersection(q_words_question)
        score += len(common_q) * 12.0

        if norm_keywords:
            kw_words = set(norm_keywords.split())
            common_kw = q_words.intersection(kw_words)
            score += len(common_kw) * 20.0

        for word in q_words:
            if len(word) > 3:
                if word in norm_question:
                    score += 3.0
                if norm_keywords and word in norm_keywords:
                    score += 5.0

        if norm_answer:
            a_score = self._calc_score_simple(norm_query, norm_answer) * 0.5
            score += a_score

        return score

    def _calc_score_simple(self, query: str, text: str) -> float:
        if not query or not text:
            return 0.0
        q_words = set(query.split())
        t_words = set(text.split())
        if not q_words:
            return 0.0
        common = q_words.intersection(t_words)
        return len(common) / len(q_words)

    def search(self, query: str, category: Optional[str] = None, top_k: int = 5) -> List[Tuple[str, str, float]]:
        cache_key = f"{query}_{category}_{top_k}"
        if cache_key in self.cache and datetime.now() < self.cache_ttl.get(cache_key, datetime.now()):
            return self.cache[cache_key]

        norm_q = self._normalize_query(query)
        if not norm_q:
            return []

        filtered = self.faq_data
        if category:
            filtered = [item for item in self.faq_data if item.get('category') == category]

        preliminary = []
        for item in filtered:
            if self._quick_match(norm_q, item):
                preliminary.append(item)
        if not preliminary:
            preliminary = filtered[:20]

        candidates = []
        for item in preliminary[:20]:
            q_words = set(norm_q.split())
            norm_question = self._normalize_query(item['question'])
            q_words_question = set(norm_question.split())
            common = q_words.intersection(q_words_question)
            base_score = len(common) * 12.0
            norm_keywords = ' '.join(item.get('keywords', [])).lower()
            if norm_keywords:
                kw_words = set(norm_keywords.split())
                common_kw = q_words.intersection(kw_words)
                base_score += len(common_kw) * 20.0
            candidates.append((item, base_score))

        candidates.sort(key=lambda x: x[1], reverse=True)
        top_candidates = [item for item, _ in candidates[:10]]

        results = []
        for item in top_candidates:
            score = self._calculate_full_score(norm_q, item)
            if score > 0:
                results.append((item['question'], item['answer'], min(score, 100.0)))

        results.sort(key=lambda x: x[2], reverse=True)
        top = results[:top_k]

        if len(self.cache) >= self.max_cache_size:
            oldest = next(iter(self.cache_ttl))
            del self.cache[oldest]
            del self.cache_ttl[oldest]

        self.cache[cache_key] = top
        self.cache_ttl[cache_key] = datetime.now() + timedelta(hours=1)
        return top

    def suggest_correction(self, query: str, top_k: int = 3) -> List[str]:
        if not query or not self.faq_data:
            return []
        norm_query = self._normalize_query(query)
        if not norm_query or len(norm_query) < 3:
            return []
        candidates = []
        for item in self.faq_data[:50]:
            norm_question = self._normalize_query(item['question'])
            if norm_question:
                dist = levenshtein_distance(norm_query, norm_question)
                if dist <= 5:
                    candidates.append((item['question'], dist))
        candidates.sort(key=lambda x: x[1])
        return [q for q, _ in candidates[:top_k]]

    def refresh_data(self):
        self.faq_data = self._load_faq_data()
        self.cache.clear()
        self.cache_ttl.clear()
        logger.info("üîÑ BuiltinSearchEngine: –¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")

# ------------------------------------------------------------
#  –ê–î–ê–ü–¢–ï–† –î–õ–Ø –í–ù–ï–®–ù–ï–ì–û SEARCH ENGINE (–° –ê–ù–ê–õ–ò–ó–û–ú –°–ò–ì–ù–ê–¢–£–†–´!)
# ------------------------------------------------------------
class ExternalSearchEngineAdapter:
    def __init__(self, external_engine):
        self._engine = external_engine
        self._search_method = getattr(external_engine, 'search', None)
        if not self._search_method:
            raise AttributeError("–í–Ω–µ—à–Ω–∏–π –¥–≤–∏–∂–æ–∫ –Ω–µ –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥–∞ search")

        # üî• –ê–ù–ê–õ–ò–ó –°–ò–ì–ù–ê–¢–£–†–´ ‚Äî –û–°–¢–ê–í–õ–ï–ù –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
        sig = inspect.signature(self._search_method)
        self._has_category = 'category' in sig.parameters
        self._supports_top_k = 'top_k' in sig.parameters
        logger.info(f"üîß –í–Ω–µ—à–Ω–∏–π –¥–≤–∏–∂–æ–∫: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ category={self._has_category}, top_k={self._supports_top_k}")

    def search(self, query: str, category: Optional[str] = None, top_k: int = 5) -> List[Tuple[str, str, float]]:
        try:
            kwargs = {'query': query}
            if self._supports_top_k:
                kwargs['top_k'] = top_k
            if self._has_category and category is not None:
                kwargs['category'] = category

            result = self._search_method(**kwargs)

            if isinstance(result, list):
                result = result[:top_k]
            return self._normalize_result(result)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤–Ω–µ—à–Ω–µ–º –ø–æ–∏—Å–∫–æ–≤–æ–º –¥–≤–∏–∂–∫–µ: {e}")
            return []

    def _normalize_result(self, result: Any) -> List[Tuple[str, str, float]]:
        normalized = []
        if isinstance(result, list):
            for item in result:
                if isinstance(item, tuple) and len(item) >= 3:
                    normalized.append((str(item[0]), str(item[1]), float(item[2])))
                elif isinstance(item, dict):
                    question = item.get('question', item.get('Question', ''))
                    answer = item.get('answer', item.get('Answer', ''))
                    score = item.get('score', item.get('Score', 0.0))
                    normalized.append((question, answer, float(score)))
                elif hasattr(item, 'question') and hasattr(item, 'answer'):
                    score = getattr(item, 'score', getattr(item, 'Score', 0.0))
                    normalized.append((item.question, item.answer, float(score)))
        return normalized

    @property
    def cache(self):
        return getattr(self._engine, 'cache', {})

    @property
    def faq_data(self):
        if hasattr(self._engine, 'faq_data'):
            raw = self._engine.faq_data
            normalized = []
            for item in raw:
                if isinstance(item, dict):
                    norm_item = {
                        'id': item.get('id', hash(item.get('question', '')) % 1000000),
                        'question': item.get('question', ''),
                        'answer': item.get('answer', ''),
                        'category': item.get('category', '–ë–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏'),
                        'keywords': item.get('keywords', []) if isinstance(item.get('keywords'), list) else str(item.get('keywords', '')).split(', ')
                    }
                else:
                    norm_item = {
                        'id': getattr(item, 'id', hash(getattr(item, 'question', '')) % 1000000),
                        'question': getattr(item, 'question', ''),
                        'answer': getattr(item, 'answer', ''),
                        'category': getattr(item, 'category', '–ë–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏'),
                        'keywords': getattr(item, 'keywords', []) if isinstance(getattr(item, 'keywords', []), list) else str(getattr(item, 'keywords', '')).split(', ')
                    }
                normalized.append(norm_item)
            return normalized
        return []

    def suggest_correction(self, query: str, top_k: int = 3) -> List[str]:
        if hasattr(self._engine, 'suggest_correction'):
            return self._engine.suggest_correction(query, top_k)
        return []

    def refresh_data(self):
        if hasattr(self._engine, 'refresh_data'):
            self._engine.refresh_data()
            logger.info("üîÑ ExternalSearchEngineAdapter: –¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤–æ –≤–Ω–µ—à–Ω–µ–º –¥–≤–∏–∂–∫–µ")

# ------------------------------------------------------------
#  –°–ò–°–¢–ï–ú–ê –ü–û–î–ü–ò–°–û–ö (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
# ------------------------------------------------------------
SUBSCRIBERS_FILE = 'subscribers.json'
subscribers_lock = asyncio.Lock()
_subscribers_cache = None
_subscribers_cache_loaded = False

async def load_subscribers():
    global _subscribers_cache, _subscribers_cache_loaded
    if _subscribers_cache_loaded:
        return _subscribers_cache
    try:
        async with subscribers_lock:
            with open(SUBSCRIBERS_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                _subscribers_cache = data.get('subscribers', [])
    except FileNotFoundError:
        _subscribers_cache = []
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤: {e}")
        _subscribers_cache = []
    _subscribers_cache_loaded = True
    return _subscribers_cache

async def save_subscribers(subscribers: List[int]):
    global _subscribers_cache
    async with subscribers_lock:
        with open(SUBSCRIBERS_FILE, 'w', encoding='utf-8') as f:
            json.dump({'subscribers': subscribers, 'updated': datetime.now().isoformat()}, f, ensure_ascii=False, indent=2)
        _subscribers_cache = subscribers

async def add_subscriber(user_id: int):
    subs = await load_subscribers()
    if user_id not in subs:
        subs.append(user_id)
        await save_subscribers(subs)
        return True
    return False

async def remove_subscriber(user_id: int):
    subs = await load_subscribers()
    if user_id in subs:
        subs.remove(user_id)
        await save_subscribers(subs)
        return True
    return False

async def get_subscribers() -> List[int]:
    return await load_subscribers()

async def ensure_subscribed(user_id: int):
    await add_subscriber(user_id)

# ------------------------------------------------------------
#  –ü–ï–†–ò–û–î–ò–ß–ï–°–ö–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï –ü–û–î–ü–ò–°–ß–ò–ö–û–í
# ------------------------------------------------------------
async def periodic_subscriber_save():
    while True:
        await asyncio.sleep(300)
        try:
            subs = await load_subscribers()
            await save_subscribers(subs)
            logger.info(f"‚úÖ –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤: {len(subs)} –∑–∞–ø–∏—Å–µ–π")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤: {e}")

# ------------------------------------------------------------
#  –°–ò–°–¢–ï–ú–ù–´–ï –°–û–û–ë–©–ï–ù–ò–Ø (EDITABLE)
# ------------------------------------------------------------
MESSAGES_FILE = 'messages.json'
messages_lock = asyncio.Lock()
DEFAULT_MESSAGES = {
    "welcome": {
        "title": "–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ",
        "text": "üëã –ü—Ä–∏–≤–µ—Ç, {first_name}!\n"
                "–Ø HR-–±–æ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ <b>–ú–µ—á–µ–ª</b>. –ü–æ–º–æ–≥—É —Å –∫–∞–¥—Ä–æ–≤—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏.\n"
                "üìå –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å ‚Äî —è –ø–æ–∏—â—É –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n"
                "/help ‚Äî –ø–æ–¥—Å–∫–∞–∑–∫–∏\n"
                "/categories ‚Äî –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤\n"
                "/feedback ‚Äî –æ—Ç–∑—ã–≤ / –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n"
                "üí¨ –ú–æ–∂–Ω–æ —Ç–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä—É—Å—Å–∫–∏–µ –∫–æ–º–∞–Ω–¥—ã:\n"
                "/—Å—Ç–∞—Ä—Ç, /–ø–æ–º–æ—â—å, /–∫–∞—Ç–µ–≥–æ—Ä–∏–∏, /–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"
    },
    "help": {
        "title": "–ü–æ–º–æ—â—å",
        "text": "‚ùì <b>–ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è:</b>\n"
                "1. –ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏.\n"
                "2. –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é —á–µ—Ä–µ–∑ –¥–≤–æ–µ—Ç–æ—á–∏–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n"
                "<i>–æ—Ç–ø—É—Å–∫: –∫–∞–∫ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏?</i>\n"
                "3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /categories –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ç–µ–º—ã.\n"
                "üìû HR: +7 (3519) 25-60-00, hr@mechel.ru"
    },
    "no_results": {
        "title": "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ",
        "text": "üòï –ù–µ –Ω–∞—à—ë–ª –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å /categories –¥–ª—è –≤—ã–±–æ—Ä–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–ª–∏ /feedback /–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."
    },
    "suggestions": {
        "title": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é",
        "text": "üòï –ù–µ –Ω–∞—à—ë–ª —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è ¬´{query}¬ª.\n"
                "–í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É:\n"
                "{suggestions}\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ /feedback /–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."
    },
    "feedback_ack": {
        "title": "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤ / –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ",
        "text": "üôè –°–ø–∞—Å–∏–±–æ –∑–∞ –≤–∞—à–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ! –ú—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –µ–≥–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º."
    },
    "greeting_response": {
        "title": "–û—Ç–≤–µ—Ç –Ω–∞ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ",
        "text": "üëã –ü—Ä–∏–≤–µ—Ç! –Ø HR-–±–æ—Ç –ú–µ—á–µ–ª. –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"
    },
    "subscribe_success": {
        "title": "–ü–æ–¥–ø–∏—Å–∫–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∞",
        "text": "‚úÖ –í—ã –ø–æ–¥–ø–∏—Å–∞–ª–∏—Å—å –Ω–∞ —Ä–∞—Å—Å—ã–ª–∫—É –Ω–æ–≤–æ—Å—Ç–µ–π! –¢–µ–ø–µ—Ä—å –≤—ã –±—É–¥–µ—Ç–µ –ø–æ–ª—É—á–∞—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏–∏."
    },
    "unsubscribe_success": {
        "title": "–ü–æ–¥–ø–∏—Å–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞",
        "text": "‚úÖ –í—ã –æ—Ç–ø–∏—Å–∞–ª–∏—Å—å –æ—Ç —Ä–∞—Å—Å—ã–ª–∫–∏. –ï—Å–ª–∏ –ø–µ—Ä–µ–¥—É–º–∞–µ—Ç–µ, –≤—Å–µ–≥–¥–∞ –º–æ–∂–µ—Ç–µ –ø–æ–¥–ø–∏—Å–∞—Ç—å—Å—è —Å–Ω–æ–≤–∞ –∫–æ–º–∞–Ω–¥–æ–π /subscribe."
    },
    "already_subscribed": {
        "title": "–£–∂–µ –ø–æ–¥–ø–∏—Å–∞–Ω—ã",
        "text": "‚ÑπÔ∏è –í—ã —É–∂–µ –ø–æ–¥–ø–∏—Å–∞–Ω—ã –Ω–∞ —Ä–∞—Å—Å—ã–ª–∫—É."
    },
    "not_subscribed": {
        "title": "–ù–µ –ø–æ–¥–ø–∏—Å–∞–Ω—ã",
        "text": "‚ÑπÔ∏è –í—ã –Ω–µ –ø–æ–¥–ø–∏—Å–∞–Ω—ã –Ω–∞ —Ä–∞—Å—Å—ã–ª–∫—É. –ß—Ç–æ–±—ã –ø–æ–¥–ø–∏—Å–∞—Ç—å—Å—è, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /subscribe."
    }
}

async def load_messages():
    try:
        async with messages_lock:
            with open(MESSAGES_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for key, default in DEFAULT_MESSAGES.items():
                    if key not in data:
                        data[key] = default
                    else:
                        if 'text' not in data[key]:
                            data[key]['text'] = default.get('text', '')
                        if 'title' not in data[key]:
                            data[key]['title'] = default.get('title', key)
                return data
    except FileNotFoundError:
        async with messages_lock:
            with open(MESSAGES_FILE, 'w', encoding='utf-8') as f:
                json.dump(DEFAULT_MESSAGES, f, ensure_ascii=False, indent=2)
            return DEFAULT_MESSAGES.copy()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π: {e}")
        return DEFAULT_MESSAGES.copy()

async def save_messages(messages: Dict):
    async with messages_lock:
        with open(MESSAGES_FILE, 'w', encoding='utf-8') as f:
            json.dump(messages, f, ensure_ascii=False, indent=2)

async def get_message(key: str, **kwargs) -> str:
    msgs = await load_messages()
    entry = msgs.get(key, DEFAULT_MESSAGES.get(key, {}))
    template = entry.get('text', '')
    if kwargs and template:
        try:
            return template.format(**kwargs)
        except KeyError:
            return template
    return template

# ------------------------------------------------------------
#  –ì–õ–û–ë–ê–õ–¨–ù–´–ï –û–ë–™–ï–ö–¢–´
# ------------------------------------------------------------
application: Optional[Application] = None
search_engine: Optional[Union[BuiltinSearchEngine, ExternalSearchEngineAdapter]] = None
bot_stats: Optional[BotStatistics] = None

# ------------------------------------------------------------
#  –ë–õ–û–ö–ò–†–û–í–ö–ò –î–õ–Ø –†–ê–ë–û–¢–´ –° JSON
# ------------------------------------------------------------
faq_lock = asyncio.Lock()

# ------------------------------------------------------------
#  –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ------------------------------------------------------------
async def _reply_or_edit(update: Update, text: str, parse_mode: str = 'HTML', reply_markup=None):
    if update.message:
        return await update.message.reply_text(text, parse_mode=parse_mode, reply_markup=reply_markup)
    elif update.callback_query:
        await update.callback_query.edit_message_text(text, parse_mode=parse_mode, reply_markup=reply_markup)
        return None
    else:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø update –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è")
        return None

# ------------------------------------------------------------
#  –†–ê–ë–û–¢–ê –° FAQ.JSON (CRUD)
# ------------------------------------------------------------
async def load_faq_json():
    try:
        async with faq_lock:
            with open('faq.json', 'r', encoding='utf-8') as f:
                return json.load(f)
    except FileNotFoundError:
        return []
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ faq.json: {e}")
        return []

async def save_faq_json(data: List[Dict]):
    async with faq_lock:
        with open('faq.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    if search_engine and hasattr(search_engine, 'refresh_data'):
        search_engine.refresh_data()

async def get_next_faq_id() -> int:
    data = await load_faq_json()
    if not data:
        return 1
    max_id = max((item.get('id', 0) for item in data), default=0)
    return max_id + 1

# ------------------------------------------------------------
#  POST_INIT
# ------------------------------------------------------------
async def post_init(application: Application):
    logger.info("‚úÖ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Telegram –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤–æ –∏ –∑–∞–ø—É—â–µ–Ω–æ")

# ------------------------------------------------------------
#  –ö–û–ú–ê–ù–î–´ /–ß–¢–û_–ú–û–ì–£ –ò /–ê–î–ú–ò–ù
# ------------------------------------------------------------
async def what_can_i_do(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    text = (
        "üìã <b>–ß—Ç–æ —è —É–º–µ—é:</b>\n"
        "‚Ä¢ –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ HR-–≤–æ–ø—Ä–æ—Å—ã (–ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ)\n"
        "‚Ä¢ –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: /categories\n"
        "‚Ä¢ –ü—Ä–∏–Ω–∏–º–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: /feedback\n"
        "‚Ä¢ –ü—Ä–∏—Å—ã–ª–∞—Ç—å –º–µ–º—ã: /–º–µ–º\n"
        "‚Ä¢ –ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ —Ä–∞—Å—Å—ã–ª–∫—É: /subscribe\n\n"
        "üí° –°–æ–≤–µ—Ç: –º–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å ¬´–æ—Ç–ø—É—Å–∫: –∫–∞–∫ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏?¬ª ‚Äî —è –Ω–∞–π–¥—É —Ç–æ—á–Ω–µ–µ!"
    )
    await update.message.reply_text(text, parse_mode='HTML')

async def admin_panel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.id not in ADMIN_IDS:
        return
    text = (
        "üëë <b>–ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å</b>\n"
        "‚Ä¢ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: /stats [day|week|month]\n"
        "‚Ä¢ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ FAQ: /faq ‚Üí –≤–µ–±-–ø–∞–Ω–µ–ª—å\n"
        "‚Ä¢ –†–∞—Å—Å—ã–ª–∫–∞: /broadcast –∏–ª–∏ /—Ä–∞—Å—Å—ã–ª–∫–∞\n"
        "‚Ä¢ –≠–∫—Å–ø–æ—Ä—Ç: /export\n"
        "‚Ä¢ –û—Ç–∑—ã–≤—ã: /feedbacks\n"
        "‚Ä¢ –ú–µ–º—ã: /memsub, /memunsub\n"
        "‚Ä¢ –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: " + BASE_URL
    )
    await update.message.reply_text(text, parse_mode='HTML')

# ------------------------------------------------------------
#  –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ë–û–¢–ê
# ------------------------------------------------------------
async def init_bot():
    global application, search_engine, bot_stats
    logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –≤–µ—Ä—Å–∏–∏ 12.45...")
    try:
        use_builtin = False
        try:
            from search_engine import EnhancedSearchEngine
            ext_engine = EnhancedSearchEngine(max_cache_size=1000)
            search_engine = ExternalSearchEngineAdapter(ext_engine)
            test_result = search_engine.search("—Ç–µ—Å—Ç", top_k=1)
            if test_result is not None:
                logger.info("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω EnhancedSearchEngine –∏–∑ search_engine.py (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–µ—á—ë—Ç–∫–∏–π –ø–æ–∏—Å–∫)")
            else:
                raise ImportError("–¢–µ—Å—Ç –Ω–µ –ø—Ä–æ–π–¥–µ–Ω")
        except (ImportError, Exception) as e:
            logger.debug(f"EnhancedSearchEngine –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç: {e}")
            try:
                from search_engine import SearchEngine as ExternalSearchEngine
                ext_engine = ExternalSearchEngine()
                search_engine = ExternalSearchEngineAdapter(ext_engine)
                test_result = search_engine.search("—Ç–µ—Å—Ç", top_k=1)
                if test_result is not None:
                    logger.info("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω SearchEngine –∏–∑ search_engine.py (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–µ—á—ë—Ç–∫–∏–π –ø–æ–∏—Å–∫)")
                else:
                    raise ImportError("–¢–µ—Å—Ç –Ω–µ –ø—Ä–æ–π–¥–µ–Ω")
            except (ImportError, Exception) as e2:
                logger.debug(f"–í–Ω–µ—à–Ω–∏–π SearchEngine –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç: {e2}")
                use_builtin = True

        if use_builtin:
            search_engine = BuiltinSearchEngine()
            logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π BuiltinSearchEngine (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–µ—á—ë—Ç–∫–∏–π –ø–æ–∏—Å–∫)")

        bot_stats = BotStatistics()
        logger.info("‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –º–æ–¥—É–ª—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")

        builder = ApplicationBuilder().token(BOT_TOKEN).post_init(post_init)
        application = builder.build()

        # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª—è –º–µ–º–æ–≤ ---
        if MEME_MODULE_AVAILABLE:
            await init_meme_handler(application.job_queue, admin_ids=ADMIN_IDS)
            logger.info("‚úÖ –ú–æ–¥—É–ª—å –º–µ–º–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        else:
            logger.warning("‚ö†Ô∏è –ú–æ–¥—É–ª—å –º–µ–º–æ–≤ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω, –∫–æ–º–∞–Ω–¥—ã /–º–µ–º, /–º–µ–º–ø–æ–¥–ø–∏—Å–∫–∞, /–º–µ–º–æ—Ç–ø–∏—Å–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")

        # --- –ê–ù–ì–õ–ò–ô–°–ö–ò–ï –ö–û–ú–ê–ù–î–´ (–≤–∫–ª—é—á–∞—è –º–µ–º—ã) ---
        application.add_handler(CommandHandler("start", start_command))
        application.add_handler(CommandHandler("help", help_command))
        application.add_handler(CommandHandler("categories", categories_command))
        application.add_handler(CommandHandler("faq", categories_command))
        application.add_handler(CommandHandler("feedback", feedback_command))
        application.add_handler(CommandHandler("suggestions", feedback_command))
        application.add_handler(CommandHandler("feedbacks", feedbacks_command))
        application.add_handler(CommandHandler("stats", stats_command))
        application.add_handler(CommandHandler("export", export_command))
        application.add_handler(CommandHandler("subscribe", subscribe_command))
        application.add_handler(CommandHandler("unsubscribe", unsubscribe_command))
        application.add_handler(CommandHandler("broadcast", broadcast_command))
        application.add_handler(CommandHandler("—á—Ç–æ_–º–æ–≥—É", what_can_i_do))
        application.add_handler(CommandHandler("–∞–¥–º–∏–Ω", admin_panel))

        # –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –º–µ–º–æ–≤
        if MEME_MODULE_AVAILABLE:
            application.add_handler(CommandHandler("mem", meme_command))
            application.add_handler(CommandHandler("memsub", meme_subscribe_command))
            application.add_handler(CommandHandler("memunsub", meme_unsubscribe_command))

        # --- –†–£–°–°–ö–ò–ï –ö–û–ú–ê–ù–î–´ –ß–ï–†–ï–ó MessageHandler ---
        async def russian_command_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
            text = update.message.text.lower()
            if text.startswith('/—Å—Ç–∞—Ä—Ç'):
                await start_command(update, context)
            elif text.startswith('/–ø–æ–º–æ—â—å'):
                await help_command(update, context)
            elif text.startswith('/–∫–∞—Ç–µ–≥–æ—Ä–∏–∏'):
                await categories_command(update, context)
            elif text.startswith('/–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è'):
                await feedback_command(update, context)
            elif text.startswith('/–æ—Ç–∑—ã–≤—ã'):
                await feedbacks_command(update, context)
            elif text.startswith('/—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞'):
                await stats_command(update, context)
            elif text.startswith('/—ç–∫—Å–ø–æ—Ä—Ç'):
                await export_command(update, context)
            elif text.startswith('/–ø–æ–¥–ø–∏—Å–∞—Ç—å—Å—è'):
                await subscribe_command(update, context)
            elif text.startswith('/–æ—Ç–ø–∏—Å–∞—Ç—å—Å—è'):
                await unsubscribe_command(update, context)
            elif text.startswith('/—Ä–∞—Å—Å—ã–ª–∫–∞'):
                await broadcast_command(update, context)
            elif text.startswith('/–º–µ–º') and MEME_MODULE_AVAILABLE:
                await meme_command(update, context)
            elif text.startswith('/–º–µ–º–ø–æ–¥–ø–∏—Å–∫–∞') and MEME_MODULE_AVAILABLE:
                await meme_subscribe_command(update, context)
            elif text.startswith('/–º–µ–º–æ—Ç–ø–∏—Å–∫–∞') and MEME_MODULE_AVAILABLE:
                await meme_unsubscribe_command(update, context)
            elif text.startswith('/—á—Ç–æ_–º–æ–≥—É'):
                await what_can_i_do(update, context)
            elif text.startswith('/–∞–¥–º–∏–Ω'):
                await admin_panel(update, context)

        application.add_handler(MessageHandler(
            filters.Regex(r'^/(—Å—Ç–∞—Ä—Ç|–ø–æ–º–æ—â—å|–∫–∞—Ç–µ–≥–æ—Ä–∏–∏|–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è|–æ—Ç–∑—ã–≤—ã|—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞|—ç–∫—Å–ø–æ—Ä—Ç|–ø–æ–¥–ø–∏—Å–∞—Ç—å—Å—è|–æ—Ç–ø–∏—Å–∞—Ç—å—Å—è|—Ä–∞—Å—Å—ã–ª–∫–∞|–º–µ–º|–º–µ–º–ø–æ–¥–ø–∏—Å–∫–∞|–º–µ–º–æ—Ç–ø–∏—Å–∫–∞|—á—Ç–æ_–º–æ–≥—É|–∞–¥–º–∏–Ω)'),
            russian_command_handler
        ))

        application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
        application.add_handler(CallbackQueryHandler(handle_callback_query))
        application.add_error_handler(error_handler)

        await application.initialize()

        if RENDER:
            webhook_url = WEBHOOK_URL + WEBHOOK_PATH
            logger.info(f"üîÑ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–µ–±—Ö—É–∫–∞ –Ω–∞ {webhook_url}...")
            result = await application.bot.set_webhook(
                url=webhook_url,
                secret_token=WEBHOOK_SECRET,
                drop_pending_updates=True,
                max_connections=40
            )
            if result:
                logger.info(f"‚úÖ –í–µ–±—Ö—É–∫ —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ {webhook_url}")
                info = await application.bot.get_webhook_info()
                if info.url == webhook_url:
                    logger.info("‚úÖ –í–µ–±—Ö—É–∫ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω")
                else:
                    logger.error(f"‚ùå –í–µ–±—Ö—É–∫ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: {info.url}")
                    return False
            else:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤–µ–±—Ö—É–∫")
                return False
        else:
            await application.bot.delete_webhook(drop_pending_updates=True)
            logger.info("‚úÖ –†–µ–∂–∏–º –ø–æ–ª–ª–∏–Ω–≥–∞ (–ª–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞)")

        asyncio.create_task(periodic_subscriber_save())
        logger.info("‚úÖ –ó–∞–ø—É—â–µ–Ω–∞ –∑–∞–¥–∞—á–∞ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤")

        # --- –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –í–ï–ë-–ú–ê–†–®–†–£–¢–û–í ---
        register_web_routes(
            app,
            application=application,
            search_engine=search_engine,
            bot_stats=bot_stats,
            load_faq_json=load_faq_json,
            save_faq_json=save_faq_json,
            get_next_faq_id=get_next_faq_id,
            load_messages=load_messages,
            save_messages=save_messages,
            get_subscribers=get_subscribers,
            WEBHOOK_SECRET=WEBHOOK_SECRET,
            BASE_URL=BASE_URL,
            MEME_MODULE_AVAILABLE=MEME_MODULE_AVAILABLE,
            get_meme_handler=get_meme_handler
        )

        logger.info("‚úÖ –ë–æ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
        return True

    except Exception as e:
        logger.critical(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–æ—Ç–∞: {e}", exc_info=True)
        return False

# ... (–æ—Å—Ç–∞–ª—å–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥, —Å–æ–æ–±—â–µ–Ω–∏–π, –≤–µ–±-—ç–Ω–¥–ø–æ–∏–Ω—Ç—ã ‚Äî –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –∫–∞–∫ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –ø–æ–ª–Ω–æ–º –∫–æ–¥–µ) ...

# ------------------------------------------------------------
#  MAIN
# ------------------------------------------------------------
async def main():
    if not await init_bot():
        logger.critical("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–æ—Ç–∞")
        sys.exit(1)
    if RENDER:
        logger.warning("‚ö†Ô∏è main() –≤—ã–∑–≤–∞–Ω –Ω–∞ Render ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ before_serving")
    else:
        logger.info("üîÑ –ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ –ø–æ–ª–ª–∏–Ω–≥–∞")
        polling_task = asyncio.create_task(application.start_polling(allowed_updates=Update.ALL_TYPES))
        config = Config()
        config.bind = [f"0.0.0.0:{PORT}"]
        await serve(app, config)
        await application.stop()
        polling_task.cancel()
        try:
            await polling_task
        except asyncio.CancelledError:
            pass

def shutdown_signal(sig):
    logger.info(f"–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª {sig}, –∏–Ω–∏—Ü–∏–∏—Ä—É–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ...")
    loop = asyncio.get_event_loop()
    loop.create_task(shutdown())

if __name__ == '__main__':
    loop = asyncio.get_event_loop()
    for sig in (signal.SIGTERM, signal.SIGINT):
        loop.add_signal_handler(sig, lambda s=sig: shutdown_signal(s))
    asyncio.run(main())
