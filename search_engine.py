"""
–£–ü–†–û–©–ï–ù–ù–´–ô –ü–û–ò–°–ö–û–í–´–ô –î–í–ò–ñ–û–ö –¢–û–õ–¨–ö–û –° CSV (–ë–ï–ó –ë–ê–ó–´ –î–ê–ù–ù–´–•)
–í–µ—Ä—Å–∏—è 3.2 - –í—Å–µ –æ—à–∏–±–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã, –ø—Ä–æ–≤–µ—Ä–∫–∞ self.config –¥–æ–±–∞–≤–ª–µ–Ω–∞
"""

import logging
import csv
import os
import hashlib
from typing import List, Optional, Tuple, Dict, Any
from dataclasses import dataclass
from collections import OrderedDict

logger = logging.getLogger(__name__)

@dataclass
class FAQEntry:
    id: int
    question: str
    answer: str
    keywords: str
    norm_keywords: str
    norm_question: str
    category: str
    usage_count: int = 0

class SearchEngine:
    """–ü–æ–∏—Å–∫–æ–≤—ã–π –¥–≤–∏–∂–æ–∫ —Ä–∞–±–æ—Ç–∞—é—â–∏–π —Ç–æ–ª—å–∫–æ —Å CSV —Ñ–∞–π–ª–∞–º–∏ –∏ —Ä–µ–∑–µ—Ä–≤–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    
    def __init__(self, config=None):
        self.faq_data: List[FAQEntry] = []
        self.config = config
        
        # LRU –∫—ç—à –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        self.cache = OrderedDict()
        self.max_cache_size = 50
        
        # –°–≤–æ—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–Ω–µ –≥–ª–æ–±–∞–ª—å–Ω–∞—è stats –∏–∑ bot.py!)
        self.stats = {
            'total_searches': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'loaded_from': 'unknown'
        }
        
        self.load_all_faq()
    
    def load_all_faq(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ FAQ –∏–∑ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        try:
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ CSV (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω—Ñ–∏–≥ –∏ —Ñ–∞–π–ª)
            if self.config:
                csv_loaded = self._load_from_csv()
                if csv_loaded:
                    logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.faq_data)} FAQ –∏–∑ CSV")
                    self.stats['loaded_from'] = f'CSV ({len(self.faq_data)} –∑–∞–ø–∏—Å–µ–π)'
                    return
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–Ω—Ñ–∏–≥–∞ –∏–ª–∏ CSV –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            self._load_fallback_data()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ FAQ: {e}")
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –Ω–∞ —Å–ª—É—á–∞–π –ø–æ–ª–Ω–æ–≥–æ —Å–±–æ—è
            self._create_minimal_data()
    
    def _load_from_csv(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ FAQ –∏–∑ CSV —Ñ–∞–π–ª–∞"""
        try:
            # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ñ–∏–≥–∞
            if not self.config:
                logger.warning("‚ö†Ô∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É CSV")
                return False
            
            csv_file = self.config.get_faq_file()
            
            if not os.path.exists(csv_file):
                logger.warning(f"‚ö†Ô∏è –§–∞–π–ª FAQ –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_file}")
                return False
            
            # –ß–∏—Ç–∞–µ–º CSV —Ñ–∞–π–ª
            self.faq_data.clear()
            
            with open(csv_file, 'r', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                
                for row_num, row in enumerate(reader, 1):
                    try:
                        category = row.get('–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–û–±—â–µ–µ').strip()
                        question = row.get('–í–æ–ø—Ä–æ—Å', '').strip()
                        answer = row.get('–û—Ç–≤–µ—Ç', '').strip()
                        keywords = row.get('–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞', '').strip()
                        norm_keywords = row.get('–ù–æ—Ä–º –∫–ª—é—á–µ–≤—ã–µ', '').strip()
                        norm_question = row.get('–ù–æ—Ä–º –≤–æ–ø—Ä–æ—Å', '').strip()
                        
                        if question and answer:
                            faq = FAQEntry(
                                id=row_num,
                                question=question,
                                answer=answer,
                                keywords=keywords,
                                norm_keywords=norm_keywords,
                                norm_question=norm_question,
                                category=category
                            )
                            self.faq_data.append(faq)
                            
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ {row_num}: {e}")
                        continue
            
            return len(self.faq_data) > 0
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ CSV: {e}")
            return False
    
    def _load_fallback_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ faq_data.py"""
        try:
            from faq_data import get_faq_data
            faq_list = get_faq_data()
            
            self.faq_data.clear()
            for i, faq_dict in enumerate(faq_list, 1):
                faq = FAQEntry(
                    id=i,
                    question=faq_dict['question'],
                    answer=faq_dict['answer'],
                    keywords=faq_dict.get('keywords', ''),
                    norm_keywords=faq_dict.get('norm_keywords', ''),
                    norm_question=faq_dict.get('norm_question', ''),
                    category=faq_dict['category']
                )
                self.faq_data.append(faq)
            
            self.stats['loaded_from'] = f'—Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ({len(self.faq_data)} –∑–∞–ø–∏—Å–µ–π)'
            logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ faq_data.py")
            
        except ImportError as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å faq_data: {e}")
            self._create_minimal_data()
    
    def _create_minimal_data(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
        self.faq_data = [
            FAQEntry(
                id=1,
                question='–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –æ—Ç–ø—É—Å–∫?',
                answer='–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –æ—Ç–¥–µ–ª –∫–∞–¥—Ä–æ–≤ —Å –∑–∞—è–≤–ª–µ–Ω–∏–µ–º –∑–∞ 2 –Ω–µ–¥–µ–ª–∏ –¥–æ –Ω–∞—á–∞–ª–∞ –æ—Ç–ø—É—Å–∫–∞.',
                keywords='–æ—Ç–ø—É—Å–∫, –æ—Ñ–æ—Ä–º–∏—Ç—å, –∫–∞–¥—Ä—ã, –∑–∞—è–≤–ª–µ–Ω–∏–µ',
                norm_keywords='–æ—Ç–ø—É—Å–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –∫–∞–¥—Ä—ã –∑–∞—è–≤–ª–µ–Ω–∏–µ',
                norm_question='–∫–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –æ—Ç–ø—É—Å–∫',
                category='–û—Ç–ø—É—Å–∫'
            ),
            FAQEntry(
                id=2,
                question='–ö–æ–≥–¥–∞ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è –∑–∞—Ä–ø–ª–∞—Ç–∞?',
                answer='–ó–∞—Ä–ø–ª–∞—Ç–∞ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è 5 –∏ 20 —á–∏—Å–ª–∞ –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—è—Ü–∞.',
                keywords='–∑–∞—Ä–ø–ª–∞—Ç–∞, –≤—ã–ø–ª–∞—Ç–∞, –¥–∞—Ç–∞, –∞–≤–∞–Ω—Å',
                norm_keywords='–∑–∞—Ä–ø–ª–∞—Ç–∞ –≤—ã–ø–ª–∞—Ç–∞ –¥–∞—Ç–∞ –∞–≤–∞–Ω—Å',
                norm_question='–∫–æ–≥–¥–∞ –≤—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è –∑–∞—Ä–ø–ª–∞—Ç–∞',
                category='–ó–∞—Ä–ø–ª–∞—Ç–∞'
            )
        ]
        self.stats['loaded_from'] = '–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä (2 –∑–∞–ø–∏—Å–∏)'
        logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö")
    
    def search(self, query: str) -> Optional[Tuple]:
        """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ FAQ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        try:
            if not query or len(query.strip()) < 2:
                return None
            
            if not self.faq_data:
                logger.warning("‚ö†Ô∏è –ü–æ–∏—Å–∫ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö FAQ")
                return None
            
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ–∏—Å–∫–æ–≤
            self.stats['total_searches'] += 1
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è –∫—ç—à–∞ (—Ö–µ—à –∑–∞–ø—Ä–æ—Å–∞)
            query_hash = hashlib.md5(query.lower().strip().encode()).hexdigest()[:12]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            if query_hash in self.cache:
                self.stats['cache_hits'] += 1
                self.cache.move_to_end(query_hash)
                return self.cache[query_hash]
            
            self.stats['cache_misses'] += 1
            
            best_match = None
            best_score = 0
            
            query_lower = query.lower().strip()
            query_words = set(query_lower.split())
            
            for faq in self.faq_data:
                score = self._calculate_relevance_score(query_lower, query_words, faq)
                
                if score > best_score:
                    best_score = score
                    best_match = (
                        faq.id,
                        faq.question,
                        faq.answer,
                        faq.category,
                        min(score, 100)
                    )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à –µ—Å–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∞
            if best_match and best_score >= 20:
                self.cache[query_hash] = best_match
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞ (LRU)
                if len(self.cache) > self.max_cache_size:
                    self.cache.popitem(last=False)
            
            return best_match if best_score >= 20 else None
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return None
    
    def _calculate_relevance_score(self, query_lower: str, query_words: set, faq: FAQEntry) -> float:
        """–†–∞—Å—á–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞ –∏ FAQ"""
        score = 0.0
        
        # 1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞
        if query_lower == faq.question.lower():
            return 100.0
        
        # 2. –ó–∞–ø—Ä–æ—Å —è–≤–ª—è–µ—Ç—Å—è –ø–æ–¥—Å—Ç—Ä–æ–∫–æ–π –≤–æ–ø—Ä–æ—Å–∞
        if query_lower in faq.question.lower():
            score += 60.0
        
        # 3. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –≤–æ–ø—Ä–æ—Å–æ–º
        if faq.norm_question and query_lower in faq.norm_question.lower():
            score += 50.0
        
        # 4. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        if faq.keywords:
            faq_keywords = set(faq.keywords.lower().replace(',', ' ').split())
            common_words = query_words.intersection(faq_keywords)
            score += len(common_words) * 15.0
        
        # 5. –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤
        for word in query_words:
            if len(word) > 3:
                if word in faq.question.lower():
                    score += 5.0
                if faq.keywords and word in faq.keywords.lower():
                    score += 8.0
        
        return score
    
    def refresh_data(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        self.load_all_faq()
        self.cache.clear()
        logger.info("üîÑ –î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
    
    def get_stats(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        categories = set()
        for faq in self.faq_data:
            if faq.category:
                categories.add(faq.category)
        
        cache_hit_rate = 0
        if self.stats['total_searches'] > 0:
            cache_hit_rate = (self.stats['cache_hits'] / self.stats['total_searches'] * 100)
        
        return {
            'faq_count': len(self.faq_data),
            'cache_size': len(self.cache),
            'categories': len(categories),
            'category_list': sorted(list(categories)),
            'total_searches': self.stats['total_searches'],
            'cache_hits': self.stats['cache_hits'],
            'cache_misses': self.stats['cache_misses'],
            'cache_hit_rate': round(cache_hit_rate, 2),
            'loaded_from': self.stats['loaded_from']
        }
