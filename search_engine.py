#!/usr/bin/env python3
"""
–ü–û–õ–ù–´–ô –ü–û–ò–°–ö–û–í–´–ô –î–í–ò–ñ–û–ö –° –ö–û–ù–¢–ï–ö–°–¢–û–ú –ò –ö–≠–®–ï–ú
–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω –¥–ª—è PostgreSQL/SQLite
"""

import json
import time
import logging
import hashlib
from typing import List, Optional, Dict, Tuple, Set
from collections import defaultdict
from dataclasses import dataclass
from datetime import datetime
import re

from config import config

logger = logging.getLogger(__name__)

@dataclass
class FAQEntry:
    """–î–∞—Ç–∞–∫–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö FAQ"""
    id: int
    question: str
    answer: str
    keywords: str
    norm_keywords: str
    norm_question: str
    category: str
    usage_count: int

class QueryExpander:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def __init__(self):
        self.synonyms = {
            '–æ—Ç–ø—É—Å–∫': ['–æ—Ç–ø—É—Å–∫', '–æ—Ç–ø—É—Å–∫–∞', '–∫–∞–Ω–∏–∫—É–ª—ã', '–æ—Ç–≥—É–ª', '–æ—Ç–¥—ã—Ö', '–æ—Ç–ø—É—Å–∫–Ω–æ–π'],
            '–∑–∞—Ä–ø–ª–∞—Ç–∞': ['–∑–∞—Ä–ø–ª–∞—Ç–∞', '–∑–∞—Ä–ø–ª–∞—Ç—É', '–∑–∞—Ä–∞–±–æ—Ç–Ω–∞—è –ø–ª–∞—Ç–∞', '–∑–∞—Ä–ø–ª–∞—Ç—ã', '–æ–∫–ª–∞–¥', '–≤—ã–ø–ª–∞—Ç–∞'],
            '–∫–æ–≥–¥–∞': ['–∫–æ–≥–¥–∞', '–≤ –∫–∞–∫–∏–µ –¥–Ω–∏', '–∫–∞–∫–æ–≥–æ —á–∏—Å–ª–∞', '–¥–∞—Ç–∞', '–¥–µ–Ω—å'],
            '–∞–≤–∞–Ω—Å': ['–∞–≤–∞–Ω—Å', '–∞–≤–∞–Ω—Å–∞', '–ø—Ä–µ–¥–æ–ø–ª–∞—Ç–∞'],
            '–±–æ–ª—å–Ω–∏—á–Ω—ã–π': ['–±–æ–ª—å–Ω–∏—á–Ω—ã–π', '–±–æ–ª—å–Ω–∏—á–Ω—ã–π –ª–∏—Å—Ç', '–±–æ–ª–µ–∑–Ω—å'],
            '–ø—Ä–æ–ø—É—Å–∫': ['–ø—Ä–æ–ø—É—Å–∫', '–¥–æ—Å—Ç—É–ø', '–∫–∞—Ä—Ç–∞ –¥–æ—Å—Ç—É–ø–∞', '–ø—Ä–æ—Ö–æ–¥–Ω–∞—è'],
            '–ø–æ—á—Ç–∞': ['–ø–æ—á—Ç–∞', 'email', '–µ–º–µ–π–ª', '—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞'],
        }
        
        self.typo_corrections = {
            '–∑–∞—Ä–ø–ø–ª–∞—Ç–∞': '–∑–∞—Ä–ø–ª–∞—Ç–∞',
            '–æ—Ç–ø—É—Å–∫–∫': '–æ—Ç–ø—É—Å–∫',
            '–±–æ–ª—å–Ω–∏—á–Ω–π': '–±–æ–ª—å–Ω–∏—á–Ω—ã–π',
            '–∫–æ—Ä–ø–∞—Ä–∞—Ç–∏–≤–Ω–∞—è': '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è',
            '–µ–º—ç–π–ª': 'email',
        }
    
    def expand_query(self, query: str) -> List[str]:
        """–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–ø–µ—á–∞—Ç–æ–∫"""
        original = query.lower().strip()
        expanded = [original]
        
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–ø–µ—á–∞—Ç–æ–∫
        corrected = self._correct_spelling(original)
        if corrected != original:
            expanded.append(corrected)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
        words = original.split()
        if len(words) <= 3:
            for word in words:
                if word in self.synonyms:
                    for synonym in self.synonyms[word][:2]:
                        new_words = words.copy()
                        idx = new_words.index(word)
                        new_words[idx] = synonym
                        new_query = ' '.join(new_words)
                        if new_query not in expanded:
                            expanded.append(new_query)
        
        return list(dict.fromkeys(expanded))[:5]
    
    def _correct_spelling(self, query: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–∏–ø–∏—á–Ω—ã—Ö –æ–ø–µ—á–∞—Ç–æ–∫"""
        words = query.split()
        corrected_words = []
        
        for word in words:
            if word in self.typo_corrections:
                corrected_words.append(self.typo_corrections[word])
            else:
                corrected_words.append(word)
        
        return ' '.join(corrected_words)

class ContextManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–∏–∞–ª–æ–≥–∞"""
    
    def __init__(self, max_contexts: int = 3, max_age: int = 86400):
        self.max_contexts = max_contexts
        self.max_age = max_age
        self.contexts = defaultdict(list)
    
    def add_context(self, user_id: int, query: str, result: Optional[tuple]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
        if result is None:
            return
        
        context_entry = {
            'query': query,
            'result': result,
            'timestamp': time.time()
        }
        
        self.contexts[user_id].append(context_entry)
        
        if len(self.contexts[user_id]) > self.max_contexts:
            self.contexts[user_id].pop(0)
    
    def get_context(self, user_id: int) -> List[dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        self._cleanup_old_contexts(user_id)
        return self.contexts.get(user_id, [])
    
    def _cleanup_old_contexts(self, user_id: Optional[int] = None):
        """–£–¥–∞–ª—è–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã"""
        current_time = time.time()
        
        if user_id:
            if user_id in self.contexts:
                self.contexts[user_id] = [
                    c for c in self.contexts[user_id]
                    if current_time - c['timestamp'] < self.max_age
                ]
                if not self.contexts[user_id]:
                    del self.contexts[user_id]
        else:
            for uid in list(self.contexts.keys()):
                self.contexts[uid] = [
                    c for c in self.contexts[uid]
                    if current_time - c['timestamp'] < self.max_age
                ]
                if not self.contexts[uid]:
                    del self.contexts[uid]

class SearchEngine:
    """–ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –¥–≤–∏–∂–æ–∫ —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    
    def __init__(self):
        self.expander = QueryExpander()
        self.context_manager = ContextManager()
        
        # –î–∞–Ω–Ω—ã–µ FAQ
        self.faq_data: List[FAQEntry] = []
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        self.keywords_index: Dict[str, List[int]] = {}
        self.question_index: Dict[str, List[int]] = {}
        self.category_index: Dict[str, List[int]] = {}
        
        # –ö—ç—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
        self.search_cache: Dict[str, tuple] = {}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_searches': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'context_used': 0,
            'total_time': 0.0,
            'last_update': time.time()
        }
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.load_all_faq()
        self._build_indexes()
        
        logger.info(f"‚úÖ –ü–æ–∏—Å–∫–æ–≤—ã–π –¥–≤–∏–∂–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω. FAQ: {len(self.faq_data)}")
    
    def load_all_faq(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö FAQ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = config.get_db_connection()
            cursor = conn.cursor()
            
            cursor.execute("SELECT * FROM faq")
            rows = cursor.fetchall()
            
            self.faq_data.clear()
            
            for row in rows:
                faq_entry = FAQEntry(
                    id=row[0],
                    question=row[1],
                    answer=row[2],
                    keywords=row[3] if len(row) > 3 else "",
                    norm_keywords=row[4] if len(row) > 4 else "",
                    norm_question=row[5] if len(row) > 5 else row[1].lower(),
                    category=row[6] if len(row) > 6 else "–û–±—â–µ–µ",
                    usage_count=row[7] if len(row) > 7 else 0
                )
                self.faq_data.append(faq_entry)
            
            conn.close()
            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.faq_data)} FAQ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ FAQ: {e}")
            self.faq_data = []
    
    def _build_indexes(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        self.keywords_index.clear()
        self.question_index.clear()
        self.category_index.clear()
        
        for faq in self.faq_data:
            faq_id = faq.id
            
            # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            if faq.category:
                category = faq.category.strip()
                if category not in self.category_index:
                    self.category_index[category] = []
                self.category_index[category].append(faq_id)
            
            # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            if faq.keywords:
                keywords_list = [k.strip().lower() for k in faq.keywords.split(',') if k.strip()]
                for keyword in keywords_list:
                    keyword_clean = self._clean_word(keyword)
                    if keyword_clean:
                        if keyword_clean not in self.keywords_index:
                            self.keywords_index[keyword_clean] = []
                        if faq_id not in self.keywords_index[keyword_clean]:
                            self.keywords_index[keyword_clean].append(faq_id)
            
            # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å–ª–æ–≤ –∏–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
            if faq.norm_question:
                words = faq.norm_question.split()
                for word in words:
                    word_clean = self._clean_word(word)
                    if word_clean and len(word_clean) > 2:
                        if word_clean not in self.question_index:
                            self.question_index[word_clean] = []
                        if faq_id not in self.question_index[word_clean]:
                            self.question_index[word_clean].append(faq_id)
        
        logger.info(f"üìä –ü–æ—Å—Ç—Ä–æ–µ–Ω—ã –∏–Ω–¥–µ–∫—Å—ã: {len(self.question_index)} —Å–ª–æ–≤, {len(self.category_index)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
    
    @staticmethod
    def _clean_word(word: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ —Å–ª–æ–≤–∞ –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏"""
        if not word:
            return ""
        word = word.strip('.,!?;:"\'()[]{}<>¬´¬ª-‚Äì‚Äî')
        return word.lower()
    
    def _calculate_relevance(self, query: str, faq: FAQEntry, expanded_queries: List[str]) -> float:
        """–†–∞—Å—á–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ FAQ –∫ –∑–∞–ø—Ä–æ—Å—É"""
        score = 0.0
        query_lower = query.lower()
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞
        if query_lower == faq.question.lower():
            score += 10.0
            return score
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        query_words = set(self._clean_word(w) for w in query_lower.split() if self._clean_word(w))
        
        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        if faq.keywords:
            faq_keywords = set(k.strip().lower() for k in faq.keywords.split(',') if k.strip())
            common_keywords = query_words.intersection(faq_keywords)
            if common_keywords:
                score += len(common_keywords) * 2.0
        
        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤ –≤ –≤–æ–ø—Ä–æ—Å–µ
        for q_word in query_words:
            if q_word in faq.norm_question:
                score += 3.0
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        for expanded in expanded_queries:
            if expanded in faq.norm_question:
                score += 2.0
        
        return max(score, 0)
    
    def _search_single(self, query: str, use_cache: bool = True) -> Optional[tuple]:
        """–ü–æ–∏—Å–∫ –æ–¥–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        start_time = time.time()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
        cache_key = hashlib.md5(query.encode()).hexdigest()[:8]
        if use_cache and cache_key in self.search_cache:
            self.stats['cache_hits'] += 1
            return self.search_cache[cache_key]
        
        self.stats['cache_misses'] += 1
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        expanded_queries = self.expander.expand_query(query)
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        candidate_ids = set()
        query_words = set(self._clean_word(w) for w in query.lower().split() if self._clean_word(w))
        
        for word in query_words:
            if word in self.keywords_index:
                candidate_ids.update(self.keywords_index[word])
            if word in self.question_index:
                candidate_ids.update(self.question_index[word])
        
        # –ï—Å–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ FAQ
        if not candidate_ids:
            candidate_ids = set(range(len(self.faq_data)))
        
        # –ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        best_match = None
        best_score = 0.0
        threshold = config.get_search_threshold()
        
        for idx in candidate_ids:
            if idx >= len(self.faq_data):
                continue
                
            faq = self.faq_data[idx]
            score = self._calculate_relevance(query, faq, expanded_queries)
            
            if score > best_score:
                best_score = score
                best_match = (faq.id, faq.question, faq.answer, faq.category, score)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        if best_match and best_score >= threshold:
            self._update_usage_count(best_match[0])
            self.search_cache[cache_key] = best_match
            
            if len(self.search_cache) > 1000:
                self.search_cache.pop(next(iter(self.search_cache)))
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        search_time = time.time() - start_time
        self.stats['total_time'] += search_time
        
        return best_match if best_score >= threshold else None
    
    def search(self, query: str, user_id: int = 0) -> Optional[tuple]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        self.stats['total_searches'] += 1
        start_time = time.time()
        
        # 1. –ü—Ä—è–º–æ–π –ø–æ–∏—Å–∫
        result = self._search_single(query)
        
        # 2. –ü–æ–∏—Å–∫ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if result is None and user_id > 0:
            context = self.context_manager.get_context(user_id)
            if context:
                last_context = context[-1]
                enhanced_query = f"{last_context['query']} {query}"
                result = self._search_single(enhanced_query)
                
                if result:
                    self.stats['context_used'] += 1
                    logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è user_id={user_id}")
        
        # 3. –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if result and user_id > 0:
            self.context_manager.add_context(user_id, query, result)
        
        return result
    
    def _update_usage_count(self, faq_id: int):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è FAQ –≤ –ë–î"""
        try:
            conn = config.get_db_connection()
            cursor = conn.cursor()
            
            placeholder = config.get_placeholder()
            query = f"UPDATE faq SET usage_count = usage_count + 1 WHERE id = {placeholder}"
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ó–∞–º–µ–Ω—è–µ–º config.execute_query –Ω–∞ cursor.execute
            cursor.execute(query, (faq_id,))
            
            conn.commit()
            conn.close()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤ –ø–∞–º—è—Ç–∏
            for faq in self.faq_data:
                if faq.id == faq_id:
                    faq.usage_count += 1
                    break
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ usage_count: {e}")
    
    def refresh_data(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î –∏ –ø–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤"""
        old_count = len(self.faq_data)
        
        self.load_all_faq()
        self._build_indexes()
        
        self.search_cache.clear()
        
        logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã: –±—ã–ª–æ {old_count}, —Å—Ç–∞–ª–æ {len(self.faq_data)} FAQ")
    
    def get_stats(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞"""
        total_searches = self.stats['total_searches']
        context_used = self.stats['context_used']
        
        avg_time = (self.stats['total_time'] / total_searches) if total_searches > 0 else 0
        
        return {
            'total_faq': len(self.faq_data),
            'total_searches': total_searches,
            'context_searches': context_used,
            'cache_hits': self.stats['cache_hits'],
            'cache_misses': self.stats['cache_misses'],
            'cache_size': len(self.search_cache),
            'avg_response_time': f"{avg_time:.3f}s",
            'context_usage_rate': f"{(context_used/total_searches*100):.1f}%" if total_searches else "0%",
            'keywords_index_size': len(self.keywords_index),
            'question_index_size': len(self.question_index),
            'categories': sorted(self.category_index.keys())
        }
